#!/usr/bin/env python3
#x3.types.db=/usr/share/collectd/types.db
#x3.types.db.custom=/usr/share/collectd/types.db.custom
#x3.zapgremlins=[^a-z0-9._/;:-]+
#x3.host=224.0.0.1
#x3.port=1250
#x3.multicast=yes
#x3.ignore=(ocspprobe|httpprobe|dnsprobe|notafterprobe|tslprobe|xkms2probe)
#x3.out.filter=^be\.(fedict|apsu|colifra)\.

#   ExtreMon Project
#   Copyright (C) 2009-2013 Frank Marien
#   frank@apsu.be
#
#   This file is part of ExtreMon.
#
#   ExtreMon is free software: you can redistribute it and/or modify
#   it under the terms of the GNU General Public License as published by
#   the Free Software Foundation, either version 3 of the License, or
#   (at your option) any later version.
#
#   ExtreMon is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with ExtreMon.  If not, see <http://www.gnu.org/licenses/>.
#
# Based on collectd_network.py:
# https://github.com/octo/collectd/blob/master/contrib/collectd_network.py
# which is Copyright (c) 2009-2013 Adrian Perez <aperez@igalia.com>
# Adrian did all the truly hard stuff parsing the binary format, back in
# 2009, and gracefully upgraded the licence to GPLv3 for me, in 2012,
# so that I could add the high-resolution versions that had been added
# to collectd in the mean time, and finally use the core code to
# produce this ExtreMon plugin, which also parses the collectd types
# files. All bugs introduced since 2009 are therefore mine.
#

import socket,struct,sys,re,time
from x3plugin import X3Out
from io import StringIO


DEFAULT_PORT = 25826
"""Default port"""

DEFAULT_IPv4_GROUP = "239.192.74.66"
"""Default IPv4 multicast group"""

DEFAULT_IPv6_GROUP = "ff18::efc0:4a42"
"""Default IPv6 multicast group"""

# Message kinds
TYPE_HOST            = 0x0000
TYPE_TIME            = 0x0001
TYPE_TIME_HR         = 0x0008
TYPE_PLUGIN          = 0x0002
TYPE_PLUGIN_INSTANCE = 0x0003
TYPE_TYPE            = 0x0004
TYPE_TYPE_INSTANCE   = 0x0005
TYPE_VALUES          = 0x0006
TYPE_INTERVAL        = 0x0007
TYPE_INTERVAL_HR     = 0x0009

# For notifications
TYPE_MESSAGE         = 0x0100
TYPE_SEVERITY        = 0x0101

# DS kinds
DS_TYPE_COUNTER      = 0
DS_TYPE_GAUGE        = 1
DS_TYPE_DERIVE       = 2
DS_TYPE_ABSOLUTE     = 3

header = struct.Struct("!2H")
number = struct.Struct("!Q")
short  = struct.Struct("!H")
double = struct.Struct("<d")


class FromCollectd(X3Out):

    BUFFER_SIZE = 16384

    def __init__(self):
      X3Out.__init__(self,max_shuttle_size=512,max_shuttle_age=.1)
      self.postprocesses={
          re.compile(r'\.processes\.[a-z0-9_-]+\.ps_cputime\.'):
                     self.post_process_plugin,
          re.compile(r'\.cpu\.[0-9]+\.cpu'):
                     self.post_clamp_percentage}

      self.ip_address_pattern=re.compile(r"(25[0-5]|2[0-4][0-9]|[01]?"
      "[0-9][0-9]?)\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\."
      "(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\."
      "(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)")
      self.ip_address_subst=r'\1-\2-\3-\4'
      self.zapgremlins_pattern=re.compile(self.config['zapgremlins'])
      self.read_types()
      self.labels={}
      self.derive_cache={}
      self.postprocess_cache={}

      try:
        self.ignore_pattern=re.compile(self.config['ignore'])
        self.ignore_cache={}
      except KeyError:
        self.ignore_cache=None
        pass

      host=self.config['host']
      port=int(self.config['port'])
      multicast=('multicast' in self.config)

      if host is None:
        multicast = True
        host = DEFAULT_IPv4_GROUP

      self.host,self.port=host,port
      self.ipv6=":" in self.host

      family,socktype,proto,canonname,sockaddr = socket.getaddrinfo(
              None if multicast else self.host, self.port,
              socket.AF_INET6 if self.ipv6 else socket.AF_UNSPEC,
              socket.SOCK_DGRAM, 0, socket.AI_PASSIVE)[0]

      self._sock = socket.socket(family, socktype, proto)
      self._sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
      self._sock.bind(sockaddr)

      if multicast:
        if hasattr(socket,"SO_REUSEPORT"):
          self._sock.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEPORT, 1)

          val=None
          if family==socket.AF_INET:
            assert "." in self.host
            val=struct.pack("4sl",socket.inet_aton(self.host),
                                                      socket.INADDR_ANY)
          elif family==socket.AF_INET6:
              raise NotImplementedError("IPv6 support not ready yet")
          else:
              raise ValueError("Unsupported network address family")

          self._sock.setsockopt(
               socket.IPPROTO_IPV6 if self.ipv6 else socket.IPPROTO_IP,
               socket.IP_ADD_MEMBERSHIP, val)
          self._sock.setsockopt(
               socket.IPPROTO_IPV6 if self.ipv6 else socket.IPPROTO_IP,
               socket.IP_MULTICAST_LOOP, 0)

      self._decoders = {
          TYPE_VALUES         : self.decode_network_values,
          TYPE_TIME           : self.decode_network_number,
          TYPE_TIME_HR        : self.decode_network_number,
          TYPE_INTERVAL       : self.decode_network_number,
          TYPE_INTERVAL_HR    : self.decode_network_number,
          TYPE_HOST           : self.decode_network_string,
          TYPE_PLUGIN         : self.decode_network_string,
          TYPE_PLUGIN_INSTANCE: self.decode_network_string,
          TYPE_TYPE           : self.decode_network_string,
          TYPE_TYPE_INSTANCE  : self.decode_network_string,
          TYPE_MESSAGE        : self.decode_network_string,
          TYPE_SEVERITY       : self.decode_network_number,
      }

      while True:
        for item in self.interpret():
          label=item[0]
          post_fn=None
          try:
            post_fn=self.postprocess_cache[label]
          except KeyError:
            for matcher, fn in self.postprocesses.items():
              if matcher.search(label):
                post_fn=fn
                break
            self.postprocess_cache[label]=post_fn

          if post_fn!=None:
            self.put(label,post_fn(item[1]))
          else:
            self.put(label,item[1])

    def decode(self, buf=None):
        """Decodes a given buffer or the next received packet.
        """
        if buf is None:
            buf=self._sock.recv(self.BUFFER_SIZE)
            self.packet_time=time.time()
        return self.decode_network_packet(buf)

    def interpret(self, iterable=None):
        """Interprets a sequence
        """
        if iterable is None:
            iterable = self.decode()
        if isinstance(iterable, str):
            iterable = self.decode(iterable)
        return self.interpret_opcodes(iterable)

    def decode_network_values(self,ptype, plen, buf):
        """Decodes a list of DS values in collectd network format
        """
        nvalues = short.unpack_from(buf, header.size)[0]
        off = header.size + short.size + nvalues
        valskip = double.size

        # Check whether our expected packet size is the reported one
        assert ((valskip + 1) * nvalues + short.size + header.size) == plen
        assert double.size == number.size

        result=[]
        for dstype in buf[header.size+short.size:off]:
            if dstype==DS_TYPE_COUNTER:
                result.append((dstype,number.unpack_from(buf,off)[0]))
                off+=valskip
            elif dstype==DS_TYPE_GAUGE:
                result.append((dstype,double.unpack_from(buf,off)[0]))
                off+=valskip
            elif dstype==DS_TYPE_DERIVE:
                result.append((dstype,number.unpack_from(buf,off)[0]))
                off+=valskip
            elif dstype==DS_TYPE_ABSOLUTE:
                result.append((dstype,number.unpack_from(buf,off)[0]))
                off+=valskip
            else:
               raise ValueError("DS type %i unsupported" % dstype)
        return result


    def decode_network_number(self,ptype, plen, buf):
        """Decodes a number (64-bit unsigned) from collectd 
           network format. """
        return number.unpack_from(buf, header.size)[0]


    def decode_network_string(self,msgtype, plen, buf):
        """Decodes a string from collectd network format.
        """
        return buf[header.size:plen-1].decode('utf-8')


    def decode_network_packet(self,buf):
      """Decodes a network packet in collectd format."""
      off=0
      blen=len(buf)
      while off<blen:
        ptype,plen=header.unpack_from(buf, off)
        if plen>blen-off:
          raise ValueError("Packet longer than amount of data in buffer")
        if ptype not in self._decoders:
          raise ValueError("Message type %i not recognized" % ptype)
        yield ptype, self._decoders[ptype](ptype, plen, buf[off:])
        off += plen

    def post_clamp_percentage(self,data):
      if data>100.0:
        return 100.0
      return data
  
    def post_process_plugin(self,data):
      return self.post_clamp_percentage(data/10000.0)

    def skiplist(self,lizst):
      for item in lizst:
        if item:
          yield item

    def cleanup_label(self,_label):
      try:
        return self.labels[_label]
      except KeyError:
        label=self.zapgremlins_pattern.sub('',
              self.ip_address_pattern.sub(self.ip_address_subst,
                                                  _label.lower()))
        self.labels[_label]=label 
        return label

    def interpret_opcodes(self,iterable):
        labelPrefixParts=[None,None,None,None,None]
        for kind, data in iterable:
          """ host.plugin(.plugin_instance).type(.type_instance) """
          pluginInstanceName=None
          if kind==TYPE_HOST:
            labelPrefixParts[0]=data
          elif kind==TYPE_PLUGIN:
            pluginName=data
            labelPrefixParts[1]=pluginName
            labelPrefixParts[2]=None
          elif kind==TYPE_PLUGIN_INSTANCE:
            if data!=labelPrefixParts[1]:
              pluginInstanceName=data
              labelPrefixParts[2]=pluginInstanceName
          elif kind==TYPE_TYPE:
            dataType=data
            labelPrefixParts[3]=data
            labelPrefixParts[4]=None
          elif kind==TYPE_TYPE_INSTANCE:
            if data!=labelPrefixParts[3]:
              labelPrefixParts[4]=data
          elif kind==TYPE_VALUES:
            """ we got the label prefix, now we get to the values """
            prefix='.'.join(self.skiplist(labelPrefixParts))
            valueTypes=self.types[dataType]
            if len(valueTypes)==0: 
              label=self.cleanup_label(prefix)
              """ if label matches ignores, don't output """
              if self.ignore_cache!=None:
                ignore=False
                try:
                  ignore=self.ignore_cache[label]
                except KeyError:
                  self.ignore_cache[label]=self.ignore_pattern.search(label)!=None
                if ignore:
                  return
              (valueType,value)=data[0]
              if valueType==DS_TYPE_DERIVE:
                try:
                  derivateData=self.derive_cache[label]
                  timeDifference=self.packet_time-derivateData[0]
                  if timeDifference>0:
                    derived=(value-derivateData[1])/timeDifference
                    yield (label,derived)
                except KeyError:
                  pass 
                self.derive_cache[label]=(self.packet_time,value)
              else:
                yield (label,round(value,3))
            else:
              """ iterate over values for this prefix """
              for i in range(len(valueTypes)):
                valueType=valueTypes[i]
                valueTypeName=valueType['name']
                """ suffix the label for this value and zap gremlins """
                if valueTypeName=='value':
                  _label=prefix
                else:
                  _label='%s.%s' % (prefix,valueTypeName)
                label=self.cleanup_label(_label)
                """ if label matches ignores, don't output """
                if self.ignore_cache!=None:
                  ignore=False
                  try:
                    ignore=self.ignore_cache[label]
                  except KeyError:
                    self.ignore_cache[label]=self.ignore_pattern.search(label)!=None
                  if ignore:
                    return
                valueType=data[i][0]
                value=data[i][1]
                if valueType==DS_TYPE_DERIVE:
                  try:
                    derivateData=self.derive_cache[label]
                    timeDifference=self.packet_time-derivateData[0]
                    if timeDifference>0:
                      derived=(value-derivateData[1])/timeDifference
                      yield (label,derived)
                  except KeyError:
                    pass 
                  self.derive_cache[label]=(self.packet_time,value)
                else:
                  yield (label,round(data[i][1],3))
  
    def read_types(self):
      self.types={}
      try:
        self.read_types_db(self.config['types.db'])
      except KeyError:
        self.log("Can't Read types.db at [%s]!" % 
                                              (self.config['types.db']))
      try:
        self.read_types_db(self.config['types.db.custom'])
      except KeyError:
        self.log("Can't Read types.db.custom at [%s]!" %
                                        (self.config['types.db.custom']))

    def read_types_db(self,path):
      td_expr=re.compile('^(?P<type>[a-z0-9_]+)\s+(?P<subtypes>.+)$')
      td_split_expr=re.compile('\s?,\s?')
      td_sub_expr=re.compile('(?P<name>[a-z_]+):(?P<type>[A-Z]+):'
                             '(?P<min>[0-9U-]+):(?P<max>[0-9U-]+)')
      with open(path,'r') as typesdb:
        for line in typesdb:
          matches=td_expr.match(line)                         
          if matches:
            type=matches.groupdict()['type']
            try:
              typedata=self.types[type]
            except KeyError:
              typedata=[]
              self.types[type]=typedata
            for subtype in td_split_expr.split(matches.groupdict()
                                                          ['subtypes']):
              matches=td_sub_expr.match(subtype)
              if matches:
                typedata.append(matches.groupdict())


if __name__=='__main__':
  FromCollectd()
